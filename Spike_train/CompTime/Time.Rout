
R version 4.2.1 (2022-06-23) -- "Funny-Looking Kid"
Copyright (C) 2022 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> set.seed(111)
> library(mcmcse)
> library("coda")
> library(bpr)
> library(foreach)
> library(doParallel)
Loading required package: iterators
Loading required package: parallel
> library(Rcpp)
> library(RcppDist)
> load("..//data_calcium_imaging_for_poisson.RData")
> str(data)
'data.frame':	920 obs. of  8 variables:
 $ cell_id   : num  5.17e+08 5.42e+08 5.17e+08 5.17e+08 5.17e+08 ...
 $ area      : Factor w/ 6 levels "VISal","VISam",..: 4 4 4 4 4 4 4 4 4 4 ...
 $ CRE.line  : Factor w/ 13 levels "Cux2-CreERT2",..: 9 9 9 9 9 9 9 9 9 9 ...
 $ depth     : num  350 350 350 350 350 350 350 350 350 350 ...
 $ mouse_id  : num  5.02e+08 5.21e+08 5.02e+08 5.02e+08 5.02e+08 ...
 $ experiment: Factor w/ 4 levels "A","B","C","C2": 3 3 3 3 3 1 1 1 1 1 ...
 $ n_spikes  : num  410 188 67 218 45 366 869 735 185 656 ...
 $ comb      : chr  "VISpScnn1a-Tg3-Cre350C" "VISpScnn1a-Tg3-Cre350C" "VISpScnn1a-Tg3-Cre350C" "VISpScnn1a-Tg3-Cre350C" ...
> 
> source("../Cov_func.R")
Registered S3 methods overwritten by 'RcppEigen':
  method               from         
  predict.fastLm       RcppArmadillo
  print.fastLm         RcppArmadillo
  summary.fastLm       RcppArmadillo
  print.summary.fastLm RcppArmadillo

Attaching package: ‘RcppEigen’

The following objects are masked from ‘package:RcppArmadillo’:

    fastLm, fastLmPure

> #library(matrixcalc)
> data$depth2 = data$depth^2
> X = model.matrix(~ ., data = data[,c(2:4,6,9)])
> str(X)
 num [1:920, 1:23] 1 1 1 1 1 1 1 1 1 1 ...
 - attr(*, "dimnames")=List of 2
  ..$ : chr [1:920] "1" "151" "9610" "9710" ...
  ..$ : chr [1:23] "(Intercept)" "areaVISam" "areaVISl" "areaVISp" ...
 - attr(*, "assign")= int [1:23] 0 1 1 1 1 1 2 2 2 2 ...
 - attr(*, "contrasts")=List of 3
  ..$ area      : chr "contr.treatment"
  ..$ CRE.line  : chr "contr.treatment"
  ..$ experiment: chr "contr.treatment"
> p = ncol(X)
> n = nrow(X)
> y = data$n_spikes
> str(y)
 num [1:920] 410 188 67 218 45 366 869 735 185 656 ...
> 
> mle.start <- c(summary(glm(y ~ X - 1, family = "poisson"(link = "log")))$coef[,1])
> str(mle.start)
 Named num [1:23] 6.2146 -0.2259 0.0752 0.0298 -0.2077 ...
 - attr(*, "names")= chr [1:23] "X(Intercept)" "XareaVISam" "XareaVISl" "XareaVISp" ...
> 
> N = seq(1e5, 1e6, length.out = 10)
> repet = 1e2
> burnin = 1:100
> nloops <- 100
> #subsize <- floor(seq(1e4, N, length = nloops))
> data = data.frame(y=y, X)
> 
> #----------------------------------------------------------------------------------#
> 
> 
> 
> bm_time = rep(0, length(N))
> lug_time = rep(0, length(N))
> ise_time = rep(0, length(N))
> sve_time = rep(0, length(N))
> cc_time = rep(0, length(N))
> mls_time = rep(0, length(N))
> 
> Table = list()
> 
> parallel::detectCores()
[1] 64
> n.cores <- parallel::detectCores() - 1
> doParallel::registerDoParallel(cores = n.cores)
> 
> 
> 
> Table = foreach(i = 1:repet, .packages = c("mcmcse"))%dopar%{
+ 	print(i)
+ 	 chain <- bpr::sample_bpr(y ~ . - 1, data = data,
+                       iter = max(N), burnin = max(burnin),
+                       prior = list(type="gaussian", b = rep(0,p), B = diag(p)*2), 
+                       pars = list(max_dist = 1e+6),
+                       state = mle.start)$sim$beta
+ 	for(j in 1:length(N)){
+ 		minichain = chain[1:N[j],]
+ 
+ 				
+ 		bm_time[j] = system.time(mcse.multi(minichain, r = 1, method = "bm", adjust = FALSE)$cov)[3]
+ 		
+ 		lug_time[j] = system.time(mcse.multi(minichain, r = 3, method = "bm", adjust = FALSE)$cov)[3]
+ 		
+ 		ise_time[j] = system.time(mcse.initseq(minichain)$cov)[3]
+ 		
+ 		sve_time[j] = system.time(mcse.multi(minichain, r = 1,method = "tukey", adjust = FALSE)$cov)[3]
+ 		
+ 		cc_time[j] = system.time(cov.sig(minichain, type = "geyer")$covariance)[3]
+ 		
+ 		mls_time[j] = system.time(cov.sig(minichain, type = "MomentLS")$covariance)[3]
+ 	}
+ 
+ 	comb = list(bm_time, lug_time, ise_time, sve_time, cc_time, mls_time)
+ 
+ 	comb
+ }
[1] 1
[1] 2
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

[1] 3
Sampling 1e+06 iterations 

[1] 4
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 5
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 6
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 7
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 8
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 9
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 10
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 11
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 12
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 13
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 14
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 15
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

[1] 16
Sampling 1e+06 iterations 

[1] 17
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 18
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 19
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

[1] 20
Sampling 1e+06 iterations 

[1] 21
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 22
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 23
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 24
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 25
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 26
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 27
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 28
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 29
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 30
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 31
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 32
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 33
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 34
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 35
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 36
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 37
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 38
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 39
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 40
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 41
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 42
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 43
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 44
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 45
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 46
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 47
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 48
[1] 49
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 50
[1] 51
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 52
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 53
[1] 54
[1] 55
[1] 56
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 57
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 58
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 59
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 60
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 61
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 62
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 63
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

Sampling 1e+06 iterations 

Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

Sampling 1e+06 iterations 

Sampling completed in 9.63799 hours 

Sampling completed in 9.6921 hours 

Sampling completed in 9.71972 hours 

Sampling completed in 9.83286 hours 

Sampling completed in 9.97401 hours 

Sampling completed in 9.98319 hours 

Sampling completed in 10.01446 hours 

Sampling completed in 10.16649 hours 

Sampling completed in 10.32391 hours 

Sampling completed in 10.42545 hours 

Sampling completed in 10.50031 hours 

[1] 100
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

Sampling completed in 10.58469 hours 

[1] 94
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

Sampling completed in 10.68286 hours 

[1] 70
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 68
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

Sampling completed in 10.73077 hours 

Sampling completed in 10.79319 hours 

Sampling completed in 10.826 hours 

[1] 78
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

Sampling completed in 11.10744 hours 

Sampling completed in 11.1412 hours 

[1] 98
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 76
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 88
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 93
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 90
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 66
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

Sampling completed in 12.14868 hours 

[1] 64
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

Sampling completed in 12.48222 hours 

Sampling completed in 12.51364 hours 

Sampling completed in 12.6102 hours 

Sampling completed in 12.63701 hours 

Sampling completed in 12.69201 hours 

Sampling completed in 13.05627 hours 

Sampling completed in 13.15199 hours 

Sampling completed in 13.17316 hours 

Sampling completed in 13.17595 hours 

Sampling completed in 13.29809 hours 

Sampling completed in 13.31083 hours 

[1] 69
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 80
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 72
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 84
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 96
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 99
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

[1] 95
Running MH sampler with a gaussian prior distribution.
Chains initialized at the provided initial points.

Sampling 1e+06 iterations 

Sampling completed in 5.84605 hours 

Sampling completed in 5.81777 hours 

Sampling completed in 5.80692 hours 

Sampling completed in 5.8691 hours 

Sampling completed in 5.68614 hours 

Sampling completed in 6.33649 hours 

Sampling completed in 5.59815 hours 

Sampling completed in 6.21686 hours 

Sampling completed in 6.55383 hours 

Sampling completed in 5.86228 hours 

Sampling completed in 6.42372 hours 

Sampling completed in 6.36915 hours 

Sampling completed in 4.65242 hours 

Sampling completed in 5.31858 hours 

Sampling completed in 5.10333 hours 

Sampling completed in 5.21411 hours 

Sampling completed in 5.13004 hours 

Sampling completed in 4.82545 hours 

Sampling completed in 4.84458 hours 

Warning message:
In mclapply(argsList, FUN, mc.preschedule = preschedule, mc.set.seed = set.seed,  :
  scheduled cores 2, 4, 8, 10, 11, 12, 14, 16, 18, 19, 20, 22, 23, 24, 26, 28, 29, 34, 38, 40, 41, 42, 43, 44, 46, 48, 49, 50, 51, 52, 53, 54, 56 did not deliver results, all values of the jobs will be affected
> 
> save(Table, N, repet, file = "Time_d.Rdata")
> 
> proc.time()
      user     system    elapsed 
3364141.27   16611.69   69984.02 
